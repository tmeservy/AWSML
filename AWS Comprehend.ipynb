{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using AWS Comprehend\n",
    "AWS Comprehend is Amazon's text analysis service. In this file, you'll learn how to call Comprehend from within SageMaker Studio. We will also look at how we can integrate Comprehend for data that we already have saved in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Comprehend client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehend = boto3.client('comprehend', region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Call the Comprehend methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tweet=\"Be of good cheer. Take life one step at a time and do the best you can each day. Life passes so swiftly. --President Nelson\"   \n",
    "\n",
    "# Key phrases\n",
    "phrases = comprehend.detect_key_phrases(Text=sample_tweet, LanguageCode='en')\n",
    "\n",
    "# Entities\n",
    "entities = comprehend.detect_entities(Text=sample_tweet, LanguageCode='en')\n",
    "\n",
    "#Sentiments\n",
    "sentiments = comprehend.detect_sentiment(Text=sample_tweet, LanguageCode='en')\n",
    "\n",
    "\n",
    "# Print the phrases:\n",
    "print('------- phrases ---------')\n",
    "for i in range(0, len(phrases['KeyPhrases'])):\n",
    "    print((phrases['KeyPhrases'][i]['Text']))\n",
    "    \n",
    "\n",
    "# Print the entities with entitity type:\n",
    "print('------- entity : entity type ---------')\n",
    "for i in range(0, len(entities['Entities'])):\n",
    "    print(entities['Entities'][i]['Text'] + ' : ' + entities['Entities'][i]['Type'] )\n",
    "    \n",
    "# Print the sentiment:\n",
    "print('------- sentiment ---------')\n",
    "print(sentiments['Sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import CSV from web + Comprehend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3 \n",
    "\n",
    "comprehend = boto3.client('comprehend', region_name='us-east-1')\n",
    "\n",
    "df = pd.read_csv(\"https://www.ishelp.info/data/tweets_aws.csv\")\n",
    "df = df.head(10)\n",
    "\n",
    "InputFieldName = \"text\"\n",
    "OutputFieldName_prefix = \"Sentiment\"\n",
    "\n",
    "#iterate over each row calling comprehend for each and taking the result and saving it back to the datafrom\n",
    "for index, row in df.iterrows():\n",
    "    #this calls the comprehend service for each item in our data frame\n",
    "    res = comprehend.detect_sentiment(Text=df.loc[index, InputFieldName], LanguageCode='en')\n",
    "    \n",
    "    #save sentiment scores to existing dataframe\n",
    "    df.loc[index,f'{OutputFieldName_prefix}_Overall'] = res['Sentiment']\n",
    "    df.loc[index,f'{OutputFieldName_prefix}_Positive'] = res[\"SentimentScore\"][\"Positive\"]\n",
    "    df.loc[index,f'{OutputFieldName_prefix}_Negative'] = res[\"SentimentScore\"][\"Negative\"]\n",
    "    df.loc[index,f'{OutputFieldName_prefix}_Neutral'] = res[\"SentimentScore\"][\"Neutral\"]\n",
    "    df.loc[index,f'{OutputFieldName_prefix}_Mixed'] = res[\"SentimentScore\"][\"Mixed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the Twitter API + Comprehend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import requests\n",
    "import boto3 \n",
    "\n",
    "comprehend = boto3.client('comprehend', region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert your Twitter API keys here\n",
    "api_key = ''\n",
    "api_secret = ''\n",
    "access_token = ''\n",
    "access_secret = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "auth = tweepy.OAuthHandler(api_key, api_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = '#cciv'\n",
    "tweets = api.search(q=tag, count = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = []\n",
    "timestamp = []\n",
    "locations = []\n",
    "sentiments = []\n",
    "positive = []\n",
    "negative = []\n",
    "neutral = []\n",
    "\n",
    "for i in range(len(tweets)):\n",
    "    d = tweets[i].text\n",
    "    ts = tweets[i].created_at\n",
    "    l = tweets[i].user.location\n",
    "    \n",
    "    if d != '':\n",
    "        res = comprehend.detect_sentiment(Text=d, LanguageCode='en')\n",
    "        s = res.get('Sentiment')\n",
    "        p = res.get('SentimentScore')['Positive']\n",
    "        neg = res.get('SentimentScore')['Negative']\n",
    "        neu = res.get('SentimentScore')['Neutral']\n",
    "    \n",
    "    timestamp.append(ts)\n",
    "    posts.append(d)\n",
    "    locations.append(l)\n",
    "    sentiments.append(s)\n",
    "    positive.append(p)\n",
    "    negative.append(neg)\n",
    "    neutral.append(neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "\n",
    "result = pd.DataFrame(OrderedDict( {\n",
    "            'tweets': posts\n",
    "         , 'location': pd.Series(locations).str.wrap(15)\n",
    "         , 'timestamp': timestamp\n",
    "         , 'sentiment': sentiments\n",
    "         , 'positiveScore': positive\n",
    "         , 'negativeScore': negative\n",
    "         , 'neutralScore' : neutral\n",
    "         }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.groupby(by='location', sort = True)['tweets'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.groupby(by='sentiment', sort = True)['tweets'].count().sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
