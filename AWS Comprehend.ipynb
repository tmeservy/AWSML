{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using AWS Comprehend\n",
    "AWS Comprehend is Amazon's text analysis service. In this file, you'll learn how to call Comprehend from within SageMaker Studio. We will also look at how we can integrate Comprehend for data that we already have saved in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed libraries\n",
    "import pandas as pd\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Comprehend client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehend = boto3.client('comprehend', region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the Comprehend methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tweet=\"Be of good cheer. Take life one step at a time and do the best you can each day. Life passes so swiftly. --President Nelson\"   \n",
    "\n",
    "# Key phrases\n",
    "phrases = comprehend.detect_key_phrases(Text=sample_tweet, LanguageCode='en')\n",
    "\n",
    "# Entities\n",
    "entities = comprehend.detect_entities(Text=sample_tweet, LanguageCode='en')\n",
    "\n",
    "#Sentiments\n",
    "sentiments = comprehend.detect_sentiment(Text=sample_tweet, LanguageCode='en')\n",
    "\n",
    "\n",
    "#Print the phrases:\n",
    "print('------- phrases ---------')\n",
    "for i in range(0, len(phrases['KeyPhrases'])):\n",
    "    print((phrases['KeyPhrases'][i]['Text']))\n",
    "    \n",
    "\n",
    "# Print the entities with entitity type:\n",
    "print('------- entity : entity type ---------')\n",
    "for i in range(0, len(entities['Entities'])):\n",
    "    print(entities['Entities'][i]['Text'] + ' : ' + entities['Entities'][i]['Type'] )\n",
    "    \n",
    "# Print the sentiment:\n",
    "print('------- sentiment ---------')\n",
    "print(sentiments['Sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import CSV from web + Comprehend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3 \n",
    "\n",
    "comprehend = boto3.client('comprehend', region_name='us-east-1')\n",
    "\n",
    "df = pd.read_csv(\"https://www.ishelp.info/data/tweets_aws.csv\")\n",
    "df = df.head(10)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InputFieldName = \"text\"\n",
    "OutputFieldName_prefix = \"Sentiment\"\n",
    "\n",
    "#iterate over each row calling comprehend for each and taking the result and saving it back to the datafrom\n",
    "for index, row in df.iterrows():\n",
    "    #this calls the comprehend service for each item in our data frame\n",
    "    res = comprehend.detect_sentiment(Text=df.loc[index, InputFieldName], LanguageCode='en')\n",
    "    \n",
    "    #save sentiment scores to existing dataframe\n",
    "    df.loc[index,f'{OutputFieldName_prefix}_Overall'] = res['Sentiment']\n",
    "    df.loc[index,f'{OutputFieldName_prefix}_Positive'] = res[\"SentimentScore\"][\"Positive\"]\n",
    "    df.loc[index,f'{OutputFieldName_prefix}_Negative'] = res[\"SentimentScore\"][\"Negative\"]\n",
    "    df.loc[index,f'{OutputFieldName_prefix}_Neutral'] = res[\"SentimentScore\"][\"Neutral\"]\n",
    "    df.loc[index,f'{OutputFieldName_prefix}_Mixed'] = res[\"SentimentScore\"][\"Mixed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the Twitter API + Comprehend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3 \n",
    "\n",
    "comprehend = boto3.client('comprehend', region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert your Twitter API keys here\n",
    "bearer_token = 'AAAAAAAAAAAAAAAAAAAAAID7MAEAAAAAH0xSsle%2FKQizZFUXaTJZCienl%2B8%3D3p59yniOFINYnvWH4seF0P6Nb5gW1FRFZ7hxKU2G6l4WfJlcgU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "client = tweepy.Client(bearer_token=bearer_token)\n",
    "\n",
    "# Replace with your own search query\n",
    "query = 'from:byu -is:retweet'\n",
    "\n",
    "tweets = client.search_recent_tweets(query=query, tweet_fields=['created_at'], max_results=100)\n",
    "\n",
    "for tweet in tweets.data:\n",
    "     print(tweet.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make dataframe out of results\n",
    "# import pandas as pd\n",
    "# import json\n",
    "\n",
    "df = pd.DataFrame(columns=['ID', 'Text', 'Sentiment', 'Positive_Score', 'Negative_Score', 'Neutral_Score', 'Mixed_Score'], dtype='object')\n",
    "for tweet in tweets.data:\n",
    "   df.loc[tweet.id]=[tweet.id,tweet.text,'','','','','']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = comprehend.detect_sentiment(Text=\"BYU is super fun!\", LanguageCode='en')\n",
    "s = res.get('Sentiment')\n",
    "p = res.get('SentimentScore')['Positive']\n",
    "neg = res.get('SentimentScore')['Negative']\n",
    "neu = res.get('SentimentScore')['Neutral']\n",
    "mix = res.get('SentimentScore')['Mixed']\n",
    "\n",
    "print(s)\n",
    "print(p)\n",
    "print(neg)\n",
    "print(neu)\n",
    "print(mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now make a iterate over the data frame and make a call to comprehend\n",
    "#to determine sentiment of each tweet\n",
    "for index, row in df.iterrows():\n",
    "    result = comprehend.detect_sentiment(Text=row['Text'], LanguageCode='en')\n",
    "    row['Sentiment'] = result.get('Sentiment')\n",
    "    row['Positive_Score'] = result.get('SentimentScore')['Positive']\n",
    "    row['Negative_Score'] = result.get('SentimentScore')['Negative']\n",
    "    row['Neutral_Score'] = result.get('SentimentScore')['Neutral']\n",
    "    row['Mixed_Score'] = result.get('SentimentScore')['Mixed']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternatively, you can pass all the data at once\n",
    "res = comprehend.batch_detect_sentiment(TextList=df['Text'].tolist(), LanguageCode='en')\n",
    "\n",
    "#And then you can merge it back in to the data frame column by column all at once\n",
    "sentiment = [result['Sentiment'] for result in res['ResultList']]\n",
    "positive_score = [result['SentimentScore']['Positive'] for result in res['ResultList']]\n",
    "negative_score = [result['SentimentScore']['Negative'] for result in res['ResultList']]\n",
    "neutral_score = [result['SentimentScore']['Neutral'] for result in res['ResultList']]\n",
    "mixed_score = [result['SentimentScore']['Mixed'] for result in res['ResultList']]\n",
    "\n",
    "#now save each column into the existing dataframe\n",
    "df['Sentiment']=sentiment\n",
    "df['Positive_Score']=positive_score\n",
    "df['Negative_Score']=negative_score\n",
    "df['Neutral_Score']=neutral_score\n",
    "df['Mixed_Score']=mixed_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the dataframe to see all the fields that were added\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
