{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the ML Pipeline in Python Jupyter Notebook\n",
    "Begin by importing the data from S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# We can import the data directly from s3. If you completed the Basic SageMaker Examples file, \n",
    "# then you have already uploaded the data to s3 using the default SageMaker bucket.\n",
    "import sagemaker\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "df = pd.read_csv(f's3://{bucket}/projectdata/insurance.csv') # If connecting to S3 bucket\n",
    "\n",
    "# Alternative 1 - You can also just hard code the s3 path\n",
    "# df = pd.read_csv('s3://bucketname/path/insurance.csv') # If connecting to S3 bucket\n",
    "\n",
    "# Alternative 2 - You can also just upload the file directly in the the SageMaker filesystem and call it directly\n",
    "# df = pd.read_csv('data/insurance.csv')\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Later to write back to CSV:\n",
    "# df.to_csv('s3://bucket-name/file.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "## Exploratory Data Analysis (i.e. Data Understanding Phase)\n",
    "### Begin with univariate analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  \n",
    "### Continue with bivariate analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(color_codes=True)\n",
    "sns.jointplot(x='bmi', y='charges', data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hexbin plot\n",
    "sns.axes_style(\"white\")\n",
    "sns.jointplot(data=df, x='bmi', y='charges', kind=\"hex\", color=\"k\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel density plot\n",
    "sns.jointplot(data=df, x=\"bmi\", y=\"charges\", kind=\"kde\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep contour plot\n",
    "f, ax = plt.subplots(figsize=(6, 6))\n",
    "cmap = sns.cubehelix_palette(as_cmap=True, dark=0, light=1, reverse=True)\n",
    "sns.kdeplot(df.bmi, df.charges, cmap=cmap, n_levels=60, shade=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=df, x=\"region\", y=\"charges\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import median\n",
    "sns.barplot(data=df, x=\"sex\", y=\"charges\", hue=\"smoker\", estimator=median, ci=\"sd\", capsize=.2, palette=\"Blues_d\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do smokers cost significantly more than non-smokers?\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "smoker_yes = df[df.smoker == 'yes']\n",
    "smoker_no = df[df.smoker == 'no']\n",
    "t, p = stats.ttest_ind(smoker_yes.charges, smoker_no.charges)\n",
    "\n",
    "print('t-Statistic:\\t' + str(round(t, 2)))\n",
    "print('p-value:\\t' + str(round(p, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do men cost significantly more than women?\n",
    "\n",
    "men = df[df.sex == 'male']\n",
    "women = df[df.sex == 'female']\n",
    "t, p = stats.ttest_ind(men.charges, women.charges)\n",
    "\n",
    "print('t-Statistic:\\t' + str(round(t, 2)))\n",
    "print('p-value:\\t' + str(round(p, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor # Import Decision Tree Regression algorithm\n",
    "from sklearn.ensemble import GradientBoostingRegressor # Import XGBoost algorithm \n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "# for a completelist of available algorithms: https://scikit-learn.org/stable/supervised_learning.html\n",
    "# Which one should I use?: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy codes for all features and not the label\n",
    "\n",
    "for col in df.columns:\n",
    "  if not pd.api.types.is_numeric_dtype(df[col]):\n",
    "    df = pd.get_dummies(df, columns=[col], prefix=col)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset in features and target variable\n",
    "\n",
    "y = df.charges # Label\n",
    "X = df.drop(columns=['charges']) # Features\n",
    "X = X.select_dtypes(np.number)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree regressor object\n",
    "clf = DecisionTreeRegressor()\n",
    "\n",
    "# Train Decision Tree regressor\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "# Predict the labels for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred,})\n",
    "output_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scikit-learn metrics module. See complete list of Classification metrics here: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "from sklearn import metrics\n",
    "    \n",
    "print(f'R squared:\\t{metrics.r2_score(y_test, y_pred)}')\n",
    "print(f'MAE:\\t\\t{metrics.mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'RMSE:\\t\\t{metrics.mean_squared_error(y_test, y_pred)**(1/2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create XGBoost regressor object\n",
    "clr = GradientBoostingRegressor()\n",
    "\n",
    "# Train Decision Tree regression\n",
    "clr = clf.fit(X_train,y_train)\n",
    "\n",
    "# Predict the labels for test dataset\n",
    "y_pred = clr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred,})\n",
    "output_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "    \n",
    "print(f'R squared:\\t{metrics.r2_score(y_test, y_pred)}')\n",
    "print(f'MAE:\\t\\t{metrics.mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'RMSE:\\t\\t{metrics.mean_squared_error(y_test, y_pred)**(1/2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model with the highest fit metric\n",
    "pickle.dump(clr, open('stored_model.sav', 'wb'))  # OPTION 1: pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...some time later\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# OPTION 1: Using pickle\n",
    "# load the model from 'stored_model.sav'\n",
    "loaded_model = pickle.load(open('stored_model.sav', 'rb'))\n",
    "print(type(loaded_model))\n",
    "\n",
    "# for a single prediction, enter a row of data and reshape into numpy array\n",
    "case = [0.543478, 0.245359, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]\n",
    "print(f'Single prediction {case}: {loaded_model.predict(np.array(case).reshape(1, -1))[0]}\\n')\n",
    "\n",
    "# for a batch prediction, enter a Pandas DataFrame or a Numpy array of arrays\n",
    "predictions = loaded_model.predict(X_test) \n",
    "batch_results = pd.DataFrame({'Actual':y_test, 'Predicted':predictions, 'Diff':(predictions - y_test)})\n",
    "print(f'MAE:\\t{batch_results.Diff.abs().mean()}\\n')\n",
    "batch_results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
