{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using AWS Rekognition\n",
    "AWS Rekognition is Amazon's deep learning image and video analysis service. In this file, you'll learn how to call Rekognition from within SageMaker Studio using files stored in S3. Amazon Rekognition has pre-trained models to identify objects, people, text, etc.  \n",
    "\n",
    "In this file we will do the following:\n",
    "* Import image data from the web and save to S3\n",
    "* Use Rekognition to detect people and the dominant emotions they display\n",
    "* Convert results from Rekognition into a Pandas dataframe that we can use in our analysis\n",
    "* Use Rekognition to detect and label a variety of objects in the images we process\n",
    "* Use Rekognition to identify text found in images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Image Data and Saving it to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will download a collection of images from the internet and then upload them to S3. In later sections we will refer to these files on S3, so let's create a couple of variables to define the bucket and the prefix (i.e., directory) where our images will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import boto3\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "bucket = \"tmeservy-mldata\" #replace this with your bucket name\n",
    "prefix = \"images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will download a sample set of images scraped from the internet. For your convenience these have been zipped up. We will use the wget shell command to get the data and then the unzip command to save those files in our local file system within SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.ishelp.info/data/images.zip -O images.zip\n",
    "# Uncompressing\n",
    "!unzip -qU -o images.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to explore the image files that you now have on your local file system. To save them out to S3, we will get the S3 client from boto and then use the upload_file method as we have done in previous sections of the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload the files to the S3 bucket\n",
    "images = glob.glob(\"images/*.jpg\")\n",
    "for filename in images:\n",
    "    boto3.Session().resource('s3').Bucket(bucket).upload_file(filename,f'{prefix}/{os.path.basename(filename)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Rekognition to Detect Faces and Emotions - Single Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rekognition has a lot of different methods that can be used to analyze images and videos. These methods use pre-trained models to identify objects in the images. We first need to get access to a Rekognition client and then we simply pass an S3 object URI to the detect_faces method.\n",
    "\n",
    "The detect faces method will find any faces for individuals in the image and will return their age range, gender, whether they are smiling, have a beard, etc. It will also associated artifacts like whether or not the individual has a beard, is wearing sunglasses, eyeglasses, etc. One of the useful states that it returns is the emotion of the individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('rekognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = client.detect_faces(\n",
    "    Image={\n",
    "        'S3Object': {\n",
    "            'Bucket': bucket,\n",
    "            'Name': f'{prefix}/3_1238858492653551617.jpg'\n",
    "        }\n",
    "    },\n",
    "    Attributes=[\n",
    "        'ALL',\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the results\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then extract the information that we are interested in from this JSON object using the approaches that we've learned previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Rekognition to Detect Faces and Emotions - Multiple Images\n",
    "\n",
    "If we want to process multiple files, we can simply get a list of the files that we want to process from S3. We'll first get the s3 client from boto and then get the files from the bucket and \"directory\" that we want by specifying the prefix that we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket(bucket)\n",
    "files = my_bucket.objects.filter(Prefix='images')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code iterates through all of the files that are returned. Notice we filter out any directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    #ignore directories\n",
    "    if file.key[-1] == \"/\":\n",
    "        continue\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this next code block iterates through all of the files in the list and makes a call for each one to the detect_faces method. It then takes the results and converts them into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([])\n",
    "i=0\n",
    "\n",
    "for file in files:\n",
    "    #ignore directories\n",
    "    if file.key[-1] == \"/\":\n",
    "        continue\n",
    "\n",
    "    #call rekognition for this next file\n",
    "    response = client.detect_faces(\n",
    "        Image={\n",
    "            'S3Object': {\n",
    "                'Bucket': file.bucket_name,\n",
    "                'Name': file.key\n",
    "            }\n",
    "        },\n",
    "        Attributes=[\n",
    "            'ALL',\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    #now add all of the facial features for every person found in the photo\n",
    "    for fd in response[\"FaceDetails\"]:\n",
    "        i+=1        \n",
    "        df.loc[i,'File'] = file.key\n",
    "        df.loc[i,'PersonID'] = i\n",
    "        df.loc[i,'AgeRange-Low'] = fd[\"AgeRange\"][\"Low\"]\n",
    "        df.loc[i,'AgeRange-High'] = fd[\"AgeRange\"][\"High\"]\n",
    "        df.loc[i,'Smile'] = fd[\"Smile\"][\"Value\"]\n",
    "        df.loc[i,'Gender'] = fd[\"Gender\"][\"Value\"]\n",
    "        df.loc[i,'Emotion'] = fd[\"Emotions\"][0][\"Type\"] #get dominant emotion\n",
    "        df.loc[i,'Emotion-Confidence'] = fd[\"Emotions\"][0][\"Confidence\"] #get dominant emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can display the results. Notice how we made sure to add the name of the file to the dataframe so that we can eventually associate these results with the correct rows in out machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing results from Rekognition Using Aggregate Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, you've now processed all of the files with Rekognition and we have results. However, we often will need to consolidate this data into a single row per record in our machine learning model. To do that, we can use some built in python and pandas functions to summarize the data for each file. \n",
    "\n",
    "One way to aggregate data is to use functions such as count, min, make, etc. The following code first creates a data frame and then adds summary information by grouping on the filename for the file that was processed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame([])\n",
    "\n",
    "#summarize stats per file\n",
    "#aggregate functions include min, max, mean, count, and more.\n",
    "df2['Count-People'] = df.groupby('File')['PersonID'].count()\n",
    "df2['Avg-AgeRange-Low'] = df.groupby('File')['AgeRange-Low'].min()\n",
    "df2['Avg-AgeRange-High'] = df.groupby('File')['AgeRange-High'].max()\n",
    "df2['Count-Smile'] = df[df['Smile']==True].groupby('File')['Smile'].count()\n",
    "df2['Percent-Smile'] = df2['Count-Smile']/df2['Count-People']\n",
    "\n",
    "#print out \n",
    "df2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas also has the ability to specify one or more aggregate functions all at once but using the agg function. The following code illustrates how we could calculate many different summary statistics all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('File').agg({'PersonID': ['count'],\n",
    "                       'AgeRange-Low': ['count','mean', 'min', 'max'],\n",
    "                       'AgeRange-High': ['count','mean', 'min', 'max'],\n",
    "                       'Smile': ['count'],\n",
    "                       })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downside to this approach is that we don't have names associated with each of the new columns. We can use a slightly different approach to name the columns as we generate the aggregate values. Notice that you can specify the a name for the new column (uses the name of the variable on the left side of the assignment operator) if you use the NamedAgg method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.groupby('File').agg(\n",
    "    NumPeople=pd.NamedAgg(column='PersonID', aggfunc='count'),\n",
    "    AgeRange_Low=pd.NamedAgg(column='AgeRange-Low', aggfunc='min'),\n",
    "    AgeRange_High=pd.NamedAgg(column='AgeRange-High', aggfunc='max'),\n",
    "                      )\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That works pretty well for summarizing numeric variables/columns but how do you handle categorical variables like the emotion displayed on the different faces? Luckily, we can use the value_counts() method to create separate columns and the associated counts of each of the different labels that might appear in the emotions column. We can also specify a default value if a specific file doesn't have a particular emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('File')['Emotion'].value_counts().unstack().fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to take all the different summarized data and combine it into one data frame. We'll use the merge function to take and existing data frame and combine it with new columns of information. Note how we use the File field to make sure that we combine the correct data together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start with df3 and add the count of different emotions and genders that were found in each of the files\n",
    "final = df3.merge(df.groupby('File')['Emotion'].value_counts().unstack().fillna(0), on='File')\n",
    "final = final.merge(df.groupby('File')['Gender'].value_counts().unstack().fillna(0),on='File')\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've generated this information, we can then save it to a csv for use in our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(\"faces.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Rekognition to Detect and Label Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a similar approach, we can detect other objects within images. Rekognition refers to these other objects as labels. Thus, we will use the detect_labels methods to process our files. Notice the parameter where we specify that we only want up to 10 labels returned. Rekognition returns the 10 labels with the highest confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([])\n",
    "i=0\n",
    "\n",
    "#files = list(files)[:2]\n",
    "\n",
    "for file in files:\n",
    "    #ignore directories\n",
    "    if file.key[-1] == \"/\":\n",
    "        continue\n",
    "\n",
    "    #print the file\n",
    "    #print(file)\n",
    "      \n",
    "    #call rekognition for this next file\n",
    "    response = client.detect_labels(\n",
    "        Image={\n",
    "            'S3Object': {\n",
    "                'Bucket': file.bucket_name,\n",
    "                'Name': file.key\n",
    "            }\n",
    "        }, MaxLabels=10\n",
    "    )\n",
    "    \n",
    "    #now add all of the labels found in this photo\n",
    "    for lb in response[\"Labels\"]:\n",
    "        i+=1 \n",
    "        df.loc[i,'File'] = file.key\n",
    "        df.loc[i,'LabelID'] = i\n",
    "        df.loc[i,'Name'] = lb[\"Name\"]\n",
    "        df.loc[i,'Confidence'] = lb[\"Confidence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the results are a little bit simpler as we chose to only extract the name of the label and the confidence score. When you use labels in machine learning models you will often just include the count of the label. Of course, we could filter out labels that were less than a certain confidence score if we wanted to. We will use the value_counts function and the unstack function to create data that we could use in our machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = df.groupby('File')['Name'].value_counts().unstack().fillna(0)\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have 132 different columns and we don't get to see the names of all of the columns. However, we can simply list out the names of the columns using the list function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the names of the columns \n",
    "list(df_labels.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we are only interested in capturing when an image contains a specific label. Assuming it was included in the results returned from Rekognition, we can simply apply filtering to our dataset before we group by the filename as seen in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Name']=='Apparel'].groupby('File')['Name'].value_counts().unstack().fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, if this data were of interest to our model we would combine this information with other relevant information and save it out to be used with our machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Rekognition to Identify Text Found in Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rekognition can also identify text that this found in images. The following code example demonstrates how the detect_text method can be used to extract text from images. Since this process is a bit more computational intensive, we will only process a few of our images by converting our files collection into a list and then specifying to only use a few images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([])\n",
    "i=0\n",
    "\n",
    "for file in list(files)[:10]:\n",
    "    #ignore directories\n",
    "    if file.key[-1] == \"/\":\n",
    "        continue\n",
    "\n",
    "    #print the file\n",
    "    #print(file)\n",
    "      \n",
    "    #call rekognition for this next file\n",
    "    response = client.detect_text(\n",
    "        Image={\n",
    "            'S3Object': {\n",
    "                'Bucket': file.bucket_name,\n",
    "                'Name': file.key\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    #now add all of the labels found in this photo\n",
    "    for td in response[\"TextDetections\"]:\n",
    "        i+=1 \n",
    "        #print(td)\n",
    "        df.loc[i,'File'] = file.key\n",
    "        df.loc[i,'TextID'] = i\n",
    "        df.loc[i,'Text'] = td[\"DetectedText\"]\n",
    "        df.loc[i,'Confidence'] = td[\"Confidence\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
