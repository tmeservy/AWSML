{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehend With Lambda\n",
    "\n",
    "Use the following function in Lambda to process a specific column of a CSV file for its sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def lambda_handler(event,  context):\n",
    "    #bring in S3 and Comprehend resources\n",
    "    s3 = boto3.resource('s3')\n",
    "    comprehend = boto3.client('comprehend', region_name='us-east-1')\n",
    "\n",
    "    #bring in CSV information from event trigger\n",
    "    for record in event['Records']:\n",
    "        #    record = event['Records'][0]\n",
    "        BUCKET_NAME = record['s3']['bucket']['name']\n",
    "        key = record['s3']['object']['key']\n",
    "\n",
    "        #column name of the field we will send to comprehend\n",
    "        inputField = \"text\"\n",
    "\n",
    "        #prefix for input and output bucket (so that we can automatically save the output file to the right place)\n",
    "        inputFolder='input'\n",
    "        outputFolder='output'\n",
    "\n",
    "        #create output filenames\n",
    "        output_file_name = os.path.splitext(os.path.basename(key))[0] + \"_processed.csv\"\n",
    "        basefolder = key.split(inputFolder)[0]\n",
    "        keyOut = os.path.join(basefolder,outputFolder,output_file_name)\n",
    "\n",
    "        #temporary files names\n",
    "        temp_file_in = '/tmp/input.csv' \n",
    "        temp_file_out = '/tmp/output.csv' \n",
    "\n",
    "        #download the file from S3 (we could read it directly but this makes it a bit easier)\n",
    "        s3.Bucket(BUCKET_NAME).download_file(key,temp_file_in)\n",
    "\n",
    "        #open input file and read it in\n",
    "        with open(temp_file_in,'r') as infile:\n",
    "            reader = list(csv.reader(infile))\n",
    "\n",
    "        #setup variable we will use to know which column to use in comprehend    \n",
    "        inputIndex=0\n",
    "        OutputFieldName_prefix = \"Sentiment\"\n",
    "\n",
    "        #read in file\n",
    "        firstLine=True\n",
    "        for row in reader:\n",
    "            if firstLine:\n",
    "                #find column to parse\n",
    "                index=0\n",
    "                for field in row:\n",
    "                    if field==inputField:\n",
    "                        inputIndex=index\n",
    "                    index+=1\n",
    "                    #print(f'{index} - {field}')\n",
    "\n",
    "                #add headers for new rows\n",
    "                row.append(f'{OutputFieldName_prefix}_Overall')\n",
    "                row.append(f'{OutputFieldName_prefix}_Positive')\n",
    "                row.append(f'{OutputFieldName_prefix}_Negative')\n",
    "                row.append(f'{OutputFieldName_prefix}_Neutral')\n",
    "                row.append(f'{OutputFieldName_prefix}_Mixed')\n",
    "\n",
    "                #process the rest of the lines for data\n",
    "                firstLine=False\n",
    "\n",
    "                #print(inputIndex)\n",
    "            else:\n",
    "                #call comprehend; this is where the magic happens\n",
    "                res = comprehend.detect_sentiment(Text=row[inputIndex], LanguageCode='en')\n",
    "\n",
    "                #add results from comprehend directly to the current row\n",
    "                row.append(res['Sentiment'])\n",
    "                row.append(res[\"SentimentScore\"][\"Positive\"])\n",
    "                row.append(res[\"SentimentScore\"][\"Negative\"])\n",
    "                row.append(res[\"SentimentScore\"][\"Neutral\"])\n",
    "                row.append(res[\"SentimentScore\"][\"Mixed\"])\n",
    "\n",
    "\n",
    "        #write out file\n",
    "        with open(temp_file_out, 'w', newline='') as outfile:\n",
    "            writer = csv.writer(outfile)\n",
    "            for line in reader: # reverse order\n",
    "                writer.writerow(line)\n",
    "\n",
    "        #save to s3\n",
    "        s3.Bucket(BUCKET_NAME).upload_file(temp_file_out,keyOut)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
